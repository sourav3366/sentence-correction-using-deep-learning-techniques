{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,LSTM,Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "MAX_LEN = 200\n",
    "UNITS = 256\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('Sentence_prediction.html')\n",
    "\n",
    "@app.route('/predict',methods=['POST'])\n",
    "def predict(): \n",
    "    df=pd.read_csv('/content/with_augmentation_2.csv')\n",
    "    train, validation = train_test_split(df, test_size=0.05, random_state = 859)\n",
    "    train, test = train_test_split(train, test_size=0.05, random_state = 859)\n",
    "    input_sentence = test['informal_text_inp'].iloc[0]\n",
    "    Original_Sentence   = test['normal_text_out'].iloc[0]\n",
    "    \n",
    "    if input_sentence.endswith('>'):\n",
    "        input_sentence = input_sentence[:-1]\n",
    "    if Original_Sentence.endswith('>'):\n",
    "        Original_Sentence = Original_Sentence[:-1]       \n",
    "    train.iloc[0]['informal_text_inp']= str(train.iloc[0]['informal_text_inp'])+'>'\n",
    "    train.iloc[0]['normal_text_inp']= str(train.iloc[0]['normal_text_inp'])+'>'\n",
    "    tknizer_informal = Tokenizer(filters = '\"#$%&()*+-/=@[\\\\]^_`{|}~\\t\\n', lower = False, char_level = True)\n",
    "    tknizer_informal.fit_on_texts(train['informal_text_inp'].values)\n",
    "    tknizer_normal = Tokenizer(filters = '\"#$%&()*+-/=@[\\\\]^_`{|}~\\t\\n', lower = False, char_level = True)\n",
    "    tknizer_normal.fit_on_texts(train['normal_text_inp'].values)\n",
    "\n",
    "    vocab_size_informal=len(tknizer_informal.word_index.keys())\n",
    "    vocab_size_normal=len(tknizer_normal.word_index.keys())\n",
    "    UNITS = 200\n",
    "    MAX_LEN = 200\n",
    "    model = tf.keras.models.load_model('Model_concat', custom_objects={\"loss_function\": loss_function})\n",
    "\n",
    "    inputs = [tknizer_informal.word_index.get(i, 0) for i in input_sentence]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen = MAX_LEN, padding = 'post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    result = ''\n",
    "    hidden = tf.zeros([1, UNITS]), tf.zeros([1, UNITS])\n",
    "    enc_out, state_h, state_c = model.encoder([inputs, hidden])\n",
    "    dec_hidden = [state_h, state_c]\n",
    "    dec_input = tf.expand_dims([tknizer_normal.word_index['<']], 0)\n",
    "    for t in range(MAX_LEN):\n",
    "        output, state_h, state_c = model.decoder.timestepdecoder([dec_input, enc_out, state_h, state_c])\n",
    "        predicted_id = tf.argmax(output[0]).numpy()\n",
    "        if tknizer_normal.index_word.get(predicted_id, '') == '>':\n",
    "            break\n",
    "        else:\n",
    "            result += tknizer_normal.index_word.get(predicted_id, '')\n",
    "            dec_input = tf.expand_dims([predicted_id], 0)\n",
    "    return render_template('result.html', variable=result,Original_Sentence=Original_Sentence)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
